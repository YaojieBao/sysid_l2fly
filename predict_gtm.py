#!/usr/bin/env python
"""predict.py: use long deep neural nets to predict time sequences for id of
dynamical systems.
"""

__author__ = "Vinicius Guimaraes Goecks"
__version__ = "0.0.0"
__status__ = "Prototype"
__date__ = "February 08, 2017"

# import
import numpy as np
import matplotlib.pyplot as plt

from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from keras.optimizers import SGD
from keras.layers import LSTM
from keras.models import model_from_json

from sklearn.preprocessing import MinMaxScaler
from sklearn import preprocessing
from sklearn.metrics import mean_squared_error

# --------------------------------------


class SysidModel():
    """
    Class that handles model approximation using neural nets.
    """

    def __init__(self):
        self.name = "SysidModel"

        # networks learning parameters
        epochs = 10000
        learning_rate = 0.1
        decay_rate = learning_rate / epochs
        momentum = 0.8
        self.opt = SGD(lr=learning_rate,
                       momentum=momentum,
                       decay=decay_rate,
                       nesterov=False)
        #self.opt = 'adam'
        self.loss = 'mean_squared_error'

        # appending data
        self.append_counter = 0
        self.scale_pqr = 20
        self.dt = 0.005

    def append_and_fit(self, model, s, a):
        """
        Append data generated by the model to original dataset and update current
        model training it again.
        Return updated model
        """
        # convert trajectory to correct format
        s0, a0, s1 = self.data_to_matrix(s, a)
        X, Y = self.aug_matrix(s0, a0)

        # recompile model
        model.compile(loss='mse', optimizer='adam')

        # update model fitting new data
        model.fit(X,
                  Y,
                  nb_epoch=1,
                  batch_size=1,
                  verbose=0)

        # update counter and save model


        return model

    def aug_matrix(self, s, a, n=1):
        """
        Convert time data with states and actions to matrix according to the
        desired 'look back' steps.

        Inputs
        ----------
        s: states
        a: actions
        n: steps to look back

        Outputs
        ----------
        x: past and present states and actions
        y: future states
        """
        # check steps
        assert n >= 1, "n should be >= 1"

        # get dimensions
        samples = s.shape[0]
        features = s.shape[1] + a.shape[1]
        max_rows = samples - n

        # create empty arrays for efficiency
        x = np.zeros((max_rows, n * (features)))
        y = np.zeros((max_rows, s.shape[1]))

        # flat arrays
        data = np.hstack((s, a))
        data_flat = data.flatten()

        # populate y
        j = 0  # to get correct features
        for i in range(max_rows):
            y[i, :] = s[i + n, :]
            x[i, :] = data_flat[j:(j + features * n)]
            j += features

        return x, y

    def train_id(self, s0, a0, s1, n, nb_epoch=100, batch_size=10, verbose=2):
        """
        Run deep learning for system id.

        Inputs
        ------
        s0: current state
        a0: control input
        s1: next state
        n: steps back in time
        nb_epoch: number of epochs
        batch_size: batch size for training
        verbose: 0, 1, or 2: amount of print output during training

        Outputs
        -------
        model: trained network model
        history: history of trained model

        """
        # (X) inputs: s0+a0
        # # (Y) outputs: s1
        # X = np.hstack((s0, a0))
        # Y = s1
        X, Y = self.aug_matrix(s0, a0, n)

        # get dimensions
        input_dim = X.shape[1]
        output_dim = Y.shape[1]

        # create model
        model = Sequential()
        # model.add(Dropout(0.2, input_shape=(input_dim,))) # dropout on visible layer (20%)
        model.add(Dense(220,
                        input_shape=(input_dim, ),
                        init='normal',
                        activation='relu'))
        # model.add(Dropout(0.2))
        model.add(Dense(160, init='normal', activation='relu'))
        model.add(Dropout(0.2))
        model.add(Dense(130, init='normal', activation='relu'))
        model.add(Dropout(0.2))
        model.add(Dense(output_dim, init='normal', activation='linear'))

        # compile model
        model.compile(loss=self.loss, optimizer=self.opt)

        # fit the model
        history = model.fit(X,
                            Y,
                            nb_epoch=nb_epoch,
                            batch_size=batch_size,
                            verbose=verbose)

        return history, model, X

    def data_to_matrix(self, s, a):
        """
        Convert time data with states and actions to matrix with present states,
        current actions, and future states.

        Inputs
        ----------
        s: states
        a: actions

        Outputs
        ----------
        s0: present states
        a0: present actions
        s1: future states

        """
        # # normalize the dataset
        # scaler = MinMaxScaler(feature_range=(0, 1))
        # s = scaler.fit_transform(s)
        # a = scaler.fit_transform(a)

        # since max p, q, and r is at about 20 deg/s, let's divide by 20 (scale_pqr)
        s = s/self.scale_pqr

        # discard last row of states (no future state to compare)
        s0 = s[0:-1, :]

        # discard first row of actions (normally zero)
        a0 = a[1:]

        # get next states of s0
        s1 = s[1:, :]

        return s0, a0, s1

    def validate_model(self, s, a, n, model):
        """
        Validate model on a new dataset of s and a.

        Inputs
        ----------
        s0: present states
        a0: present actions
        model: network model to validate

        Outputs
        ----------
        s1: future states

        """
        # convert dataset to matrix with n steps looking back
        s0, a0, s1 = self.data_to_matrix(s, a)

        # # normalize data
        # X = preprocessing.normalize(X, norm='l2')
        # Y = preprocessing.normalize(Y, norm='l2')

        # predict
        X, Y = self.aug_matrix(s0, a0, n)
        Y_pred = model.predict(X)

        return Y, Y_pred

    def save_model(self, model, name):
        """
        Save neural model to disk.
        """
        # save model to JSON
        model_json = model.to_json()
        with open(name+".json", "w") as json_file:
            json_file.write(model_json)

        # save weights to HDF5
        model.save_weights(name+".h5")
        print("Saved model named "+name+" to disk")

    def load_model(self, name):
        """
        Load neural model from disk.
        """
        # load json and create model
        json_file = open(name+'.json', 'r')
        loaded_model_json = json_file.read()
        json_file.close()
        loaded_model = model_from_json(loaded_model_json)

        # load weights into new model
        loaded_model.load_weights(name+'.h5')
        loaded_model.compile(loss=self.loss, optimizer=self.opt)
        self.model = loaded_model
        print("Loaded model named "+name+" from disk")

        return loaded_model

    def plot_in_out(self, Y, Y_pred, mse, mse2, Y2, Y2_pred, history):
        """
        Plotting train, test, and loss results.
        """
        ## =====================
        # load stylesheet
        try:
            plt.style.use("dwplot")
        except:
            print("Cannot use this stylesheet")

        # labels
        data_label1 = 'p [deg/s]'
        data_label2 = 'q [deg/s]'
        data_label3 = 'r [deg/s]'

        # calculate time vector
        time_train = np.arange(0,len(Y))*self.dt
        time_test = np.arange(0,len(Y2))*self.dt

        # re-scale
        Y = Y*self.scale_pqr
        Y2 = Y2*self.scale_pqr
        Y_pred = Y_pred*self.scale_pqr
        Y2_pred = Y2_pred*self.scale_pqr

        # plot (training)
        fig0 = plt.figure(0)
        #plt.suptitle('Training Data', fontsize='medium')
        for col in range(3):
            index = 311 + col
            ax = fig0.add_subplot(index)
            ax.plot(time_train, Y[:, col], 'b', label='Truth')
            ax.plot(time_train, Y_pred[:, col], 'r', label='Predicted')
            ax.set_xlim([0, time_train[-1]])
            ax.grid()
            # plt.tight_layout()
            # ax.legend(loc='best')

            # plot settings
            x_text = 0
            y_text = .8
            if index == 311:
                ax.legend(bbox_to_anchor=(0., 1.02, 1., .102),
                          loc=4,
                          ncol=2,
                          borderaxespad=0.)
                ax.set_ylabel(data_label1)
                plt.text(x_text,
                         y_text,
                         'MSE = %.4f' % mse[col],
                         weight='medium')
            elif index == 312:
                ax.set_ylabel(data_label2)
                plt.text(x_text,
                         y_text,
                         'MSE = %.4f' % mse[col],
                         weight='medium')
            elif index == 313:
                ax.set_ylabel(data_label3)
                ax.set_xlabel('Time [sec]')
                plt.text(x_text,
                         y_text,
                         'MSE = %.4f' % mse[col],
                         weight='medium')

        ## =====================
        # plot (loss)
        fig1 = plt.figure(1)
        #plt.suptitle('Training Loss', fontsize='medium')
        plt.xlabel('Epoch [unit]')
        plt.ylabel('Mean Squared Error [unit]')
        plt.grid()

        hist_list = history.history['loss']
        hist_init = int(0.0 * len(
            hist_list))  # cut first x% of the history (for scaling purposes)
        plt.plot(hist_list[hist_init:])
        plt.xlim([0, len(hist_list)])

        ## =====================
        # plot (test)
        fig2 = plt.figure(2)
        #plt.suptitle('Testing Data', fontsize='medium')
        for col in range(3):
            index = 311 + col
            ax = fig2.add_subplot(index)
            ax.plot(time_test, Y2[:, col], 'b', label='Truth')
            ax.plot(time_test, Y2_pred[:, col], 'r', label='Predicted')
            ax.set_xlim([0, time_test[-1]])
            ax.grid()
            # plt.tight_layout()
            # ax.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=4, ncol=2, borderaxespad=0.)

            # plot settings
            x_text = 0
            y_text = .8
            if index == 311:
                ax.legend(bbox_to_anchor=(0., 1.02, 1., .102),
                          loc=4,
                          ncol=2,
                          borderaxespad=0.)
                ax.set_ylabel(data_label1)
                plt.text(x_text,
                         y_text,
                         'MSE = %.4f' % mse2[col],
                         weight='medium')
            elif index == 312:
                ax.set_ylabel(data_label2)
                plt.text(x_text,
                         y_text,
                         'MSE = %.4f' % mse2[col],
                         weight='medium')
            elif index == 313:
                ax.set_ylabel(data_label3)
                ax.set_xlabel('Time [sec]')
                plt.text(x_text,
                         y_text,
                         'MSE = %.4f' % mse2[col],
                         weight='medium')

        # save plots
        fig0.savefig('./results/training.eps',dpi=600,transparent=True)
        fig1.savefig('./results/loss.eps',dpi=600,transparent=True)
        fig2.savefig('./results/testing.eps',dpi=600,transparent=True)

        # plt.show()

    def fit_model(self):
        """
        Lazy way of fitting the model.
        """
        # fix random seed for reproducibility
        np.random.seed(42)

        # load the dataset
        # dataset_s = np.loadtxt("../data/Smoothed_Data/out_latD_smooth_all.csv",
        #                        delimiter=",")
        dataset_s = np.loadtxt("../data/gtm/angular_velocity.csv",
                               delimiter=",")
        s = dataset_s[:, 1:4]

        #dataset_a2 = np.loadtxt("../data/data_in_test.csv", delimiter=",")
        # dataset_a = np.loadtxt("../data/Smoothed_Data/in_latD_smooth_all.csv",
        #                        delimiter=",")
        dataset_a = np.loadtxt("../data/gtm/doublet_sent.csv",
                               delimiter=",")
        a = dataset_a[:, 0:3]

        # convert dataset to matrix with n steps looking back
        s0, a0, s1 = self.data_to_matrix(s, a)

        # # normalize data
        # X = preprocessing.normalize(X,Y, Y_pred, mse, mse2, Y2, Y2_pred, history norm='l2')
        # Y = preprocessing.normalize(Y, norm='l2')

        # train network
        n = 1  # steps back in time
        history, model, X_check = self.train_id(s0,
                                                a0,
                                                s1,
                                                n,
                                                nb_epoch=100,
                                                batch_size=50,
                                                verbose=2)
        self.model = model

        X, Y = self.aug_matrix(s0, a0, n)
        Y_pred = model.predict(X)

        ## =====================
        # testing more data
        # load the dataset
        #dataset_s2 = np.loadtxt("../data/data_out_test.csv", delimiter=",")
        dataset_s2 = np.loadtxt("../data/gtm/angular_velocity_test.csv",
                                delimiter=",")
        s2 = dataset_s2[:, 1:4]

        dataset_a2 = np.loadtxt("../data/gtm/doublet_sent_test.csv",
                                delimiter=",")
        a2 = dataset_a2[:, 0:3]

        # validate model
        Y2, Y2_pred = self.validate_model(s2, a2, n, model)

        # compute MSE for each column (feature)
        mse2 = ((Y2 - Y2_pred)**2).mean(axis=0)
        print('Total MSE error (test) = ', sum(mse2))

        # compute MSE for each column (feature)
        mse = ((Y - Y_pred)**2).mean(axis=0)
        print('Total MSE error (training) = ', sum(mse))

        # save model and plot
        self.save_model(model, 'model')
        self.plot_in_out(Y, Y_pred, mse, mse2, Y2, Y2_pred, history)

    def compare_models(self, model1, model2):
        """
        Compare two different models to a same dataset (the test one).
        """
        # load the dataset
        #dataset_s2 = np.loadtxt("../data/data_out_test.csv", delimiter=",")
        dataset_s2 = np.loadtxt("../data/Smoothed_Data/out_smooth1.csv",
                                delimiter=",")
        s2 = dataset_s2[:, 0:4]

        dataset_a2 = np.loadtxt("../data/Smoothed_Data/in_smooth1.csv",
                                delimiter=",")
        a2 = dataset_a2[:, 0:2]
        n = 1

        # validate first model
        Y1, Y1_pred = self.validate_model(s2, a2, n, model1)
        mse1 = ((Y1 - Y1_pred)**2).mean(axis=0)
        print('Total MSE error (model1) = ', sum(mse1))

        # validate second model
        Y2, Y2_pred = self.validate_model(s2, a2, n, model2)
        mse2 = ((Y2 - Y2_pred)**2).mean(axis=0)
        print('Total MSE error (model2) = ', sum(mse2))

        # plot
        self.plot_comparison(Y1, Y1_pred, mse1, mse2, Y2, Y2_pred)

    def plot_comparison(self, Y, Y_pred, mse, mse2, Y2, Y2_pred):
        """
        Plot comparison of two different models.
        """
        ## =====================
        # load stylesheet
        try:
            plt.style.use("dwplot")
        except:
            print("Cannot use this stylesheet")

        # labels
        data_label1 = r'$\beta$ [unit]'
        data_label2 = r'$p$ [unit]'
        data_label3 = r'$q$ [unit]'
        data_label4 = r'$\phi$ [unit]'

        ## =====================
        # plot (model 1)
        fig0 = plt.figure(0)
        plt.suptitle('Model 1', fontsize='medium')
        for col in range(4):
            index = 411 + col
            ax = fig0.add_subplot(index)
            ax.plot(Y[:-1, col], 'b', label='Truth')
            ax.plot(Y_pred[:-1, col], 'r', label='Predicted')
            ax.grid()
            # plt.tight_layout()
            # ax.legend(loc='best')

            # plot settings
            x_text = 0
            y_text = .8
            if index == 411:
                ax.legend(bbox_to_anchor=(0., 1.02, 1., .102),
                          loc=4,
                          ncol=2,
                          borderaxespad=0.)
                ax.set_ylabel(data_label1)
                plt.text(x_text,
                         y_text,
                         'MSE = %.4f' % mse[col],
                         weight='medium')
            elif index == 412:
                ax.set_ylabel(data_label2)
                plt.text(x_text,
                         y_text,
                         'MSE = %.4f' % mse[col],
                         weight='medium')
            elif index == 413:
                ax.set_ylabel(data_label3)
                plt.text(x_text,
                         y_text,
                         'MSE = %.4f' % mse[col],
                         weight='medium')
            elif index == 414:
                ax.set_ylabel(data_label4)
                plt.xlabel('Time [unit]')
                plt.text(x_text,
                         y_text,
                         'MSE = %.4f' % mse[col],
                         weight='medium')

        ## =====================
        # plot (model 2)
        fig2 = plt.figure(2)
        plt.suptitle('Model 2', fontsize='medium')
        for col in range(4):
            index = 411 + col
            ax = fig2.add_subplot(index)
            ax.plot(Y2[:-1, col], 'b', label='Truth')
            ax.plot(Y2_pred[:-1, col], 'r', label='Predicted')
            ax.grid()
            # plt.tight_layout()
            # ax.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=4, ncol=2, borderaxespad=0.)

            # plot settings
            x_text = 0
            y_text = .8
            if index == 411:
                ax.legend(bbox_to_anchor=(0., 1.02, 1., .102),
                          loc=4,
                          ncol=2,
                          borderaxespad=0.)
                ax.set_ylabel(data_label1)
                plt.text(x_text,
                         y_text,
                         'MSE = %.4f' % mse2[col],
                         weight='medium')
            elif index == 412:
                ax.set_ylabel(data_label2)
                plt.text(x_text,
                         y_text,
                         'MSE = %.4f' % mse2[col],
                         weight='medium')
            elif index == 413:
                ax.set_ylabel(data_label3)
                plt.text(x_text,
                         y_text,
                         'MSE = %.4f' % mse2[col],
                         weight='medium')
            elif index == 414:
                ax.set_ylabel(data_label4)
                plt.xlabel('Time [unit]')
                plt.text(x_text,
                         y_text,
                         'MSE = %.4f' % mse2[col],
                         weight='medium')

        plt.show()



if __name__ == "__main__":
    sysid_model = SysidModel()
    sysid_model.fit_model()
